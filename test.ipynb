{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url =  'https://i.bigschool.vn/w/ddf47d/640/News/images/2017/05/Screen_Shot_2017-05-16_at_5.06.15_CH/But-tich-cua-Bac-Ho.png' #@param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m craft \u001b[39m=\u001b[39m Craft(output_dir\u001b[39m=\u001b[39moutput_dir, crop_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpoly\u001b[39m\u001b[39m\"\u001b[39m, cuda\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[39m# apply craft text detection and export detected regions to output directory\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m prediction_result \u001b[39m=\u001b[39m craft\u001b[39m.\u001b[39mdetect_text(image_path)\n\u001b[0;32m     14\u001b[0m \u001b[39m# unload models from ram/gpu\u001b[39;00m\n\u001b[0;32m     15\u001b[0m craft\u001b[39m.\u001b[39munload_craftnet_model()\n",
      "File \u001b[1;32mc:\\Users\\congp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\craft_text_detector\\__init__.py:131\u001b[0m, in \u001b[0;36mCraft.detect_text\u001b[1;34m(self, image, image_path)\u001b[0m\n\u001b[0;32m    128\u001b[0m     image \u001b[39m=\u001b[39m image_path\n\u001b[0;32m    130\u001b[0m \u001b[39m# perform prediction\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m prediction_result \u001b[39m=\u001b[39m get_prediction(\n\u001b[0;32m    132\u001b[0m     image\u001b[39m=\u001b[39;49mimage,\n\u001b[0;32m    133\u001b[0m     craft_net\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcraft_net,\n\u001b[0;32m    134\u001b[0m     refine_net\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrefine_net,\n\u001b[0;32m    135\u001b[0m     text_threshold\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext_threshold,\n\u001b[0;32m    136\u001b[0m     link_threshold\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlink_threshold,\n\u001b[0;32m    137\u001b[0m     low_text\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlow_text,\n\u001b[0;32m    138\u001b[0m     cuda\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcuda,\n\u001b[0;32m    139\u001b[0m     long_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlong_size,\n\u001b[0;32m    140\u001b[0m )\n\u001b[0;32m    142\u001b[0m \u001b[39m# arange regions\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbox\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\congp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\craft_text_detector\\predict.py:47\u001b[0m, in \u001b[0;36mget_prediction\u001b[1;34m(image, craft_net, refine_net, text_threshold, link_threshold, low_text, cuda, long_size, poly)\u001b[0m\n\u001b[0;32m     44\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     46\u001b[0m \u001b[39m# read/convert image\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m image \u001b[39m=\u001b[39m image_utils\u001b[39m.\u001b[39;49mread_image(image)\n\u001b[0;32m     49\u001b[0m \u001b[39m# resize\u001b[39;00m\n\u001b[0;32m     50\u001b[0m img_resized, target_ratio, size_heatmap \u001b[39m=\u001b[39m image_utils\u001b[39m.\u001b[39mresize_aspect_ratio(\n\u001b[0;32m     51\u001b[0m     image, long_size, interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_LINEAR\n\u001b[0;32m     52\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\congp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\craft_text_detector\\image_utils.py:13\u001b[0m, in \u001b[0;36mread_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(image) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     12\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image)\n\u001b[1;32m---> 13\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2RGB)\n\u001b[0;32m     15\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(image) \u001b[39m==\u001b[39m \u001b[39mbytes\u001b[39m:\n\u001b[0;32m     16\u001b[0m     nparr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(image, np\u001b[39m.\u001b[39muint8)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# import Craft class\n",
    "from craft_text_detector import Craft\n",
    "\n",
    "# set image path and export folder directory\n",
    "image_path = 'inputs/sample.jpg'\n",
    "output_dir = 'outputs/'\n",
    "\n",
    "# create a craft instance\n",
    "craft = Craft(output_dir=output_dir, crop_type=\"poly\", cuda=False)\n",
    "\n",
    "# apply craft text detection and export detected regions to output directory\n",
    "prediction_result = craft.detect_text(image_path)\n",
    "\n",
    "# unload models from ram/gpu\n",
    "craft.unload_craftnet_model()\n",
    "craft.unload_refinenet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "image_paths = glob.glob('outputs/*.png')\n",
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(image_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(image_paths[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5847abfd9beea167dda7d9ca7e1fb9b7b94b4eba9209f2fc13f3d9d41f07c88b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
